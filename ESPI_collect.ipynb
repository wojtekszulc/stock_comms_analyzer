{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESPI Collect\n",
    "\n",
    "This module will collect ESPI reports from GPW (Giełda Papierów Wartościowych) website and save relevant information in html and csv format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Define functions for data parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import HTML, display\n",
    "import re\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse reporting date and return format yyyymmdd\n",
    "def parse_date(soup):\n",
    "    creation_date = soup.find('td',text=re.compile(r'Data sporz')).next_sibling.next_sibling.text.strip()\n",
    "    creation_date = creation_date.replace(\"-\",\"\")\n",
    "    return creation_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse name of the reporting company\n",
    "def parse_name(soup):\n",
    "    name = soup.find('td',text=\"Nazwa emitenta\").next_sibling.next_sibling.text\n",
    "    name = name.strip().upper()\n",
    "    name = name.replace('\"', '')    \n",
    "    name = name.replace(\" W RESTRUKTURYZACJI\", \"\")\n",
    "    name = name.replace(\" W UPADŁOŚCI LIKWIDACYJNEJ\", \"\")\n",
    "    name = name.replace(\" W UPADŁOŚCI UKŁADOWEJ\", \"\")\n",
    "    name = name.replace(\" W UPADŁOŚCI\", \"\")\n",
    "    name = name.replace(\"SPÓŁKA AKCYJA\", \"SA\")\n",
    "    name = name.replace(\"SPÓŁKA ACYJNA\", \"SA\")\n",
    "    name = name.replace(\"SPÓŁKA AKCJNA\", \"SA\")\n",
    "    name = name.replace(\"SPÓLKA AKCYJNA\", \"SA\")\n",
    "    name = name.replace(\"SPÓŁKA AKCYJNA\", \"SA\")\n",
    "    name = name.replace(\"S. A.\",\"SA\")\n",
    "    name = name.replace(\"S.A.\",\"SA\")\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get text from the main part of the ESPI report\n",
    "def parse_url(soup):\n",
    "    contents = soup.find(\"div\", {'class':'dane'})\n",
    "    # Index of the report\n",
    "    section_index = contents.find_all(\"table\", {'class':'nDokument'})[0] \n",
    "    # Footer of the report - information about the reporting company\n",
    "    section_footer = contents.find_all(\"table\", {'class':'nDokument'})[1] \n",
    "    link_raport = section_index.find(\"a\")['href']\n",
    "    link_raport = link_raport[link_raport.find('#')+1:]\n",
    "    start = contents.find('a',{'name':link_raport})\n",
    "    content_table = start.parent.next_sibling.next_sibling\n",
    "    contents_nTekst = content_table.find_all(\"tr\", {'class':'nTekst'})\n",
    "    total = [(el.text) for el in contents_nTekst]\n",
    "    return ''.join(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_url_and_save(soup):\n",
    "    contents = soup.find(\"div\", {'class':'dane'})\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Collect the ESPI reports from GPW website and save relevant information to htmls files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: chrome not reachable\n  (Session info: chrome=80.0.3987.100)\n  (Driver info: chromedriver=2.41.578700 (2f1ed5f9343c13f73144538f15c00b370eda6706),platform=Linux 5.3.0-40-generic x86_64)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-63b9864d0998>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m# print(\"Error at id number: \"+str(el))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/stock_comms_analyzer_venv/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m         \"\"\"\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLOSE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mquit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/stock_comms_analyzer_venv/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m~/virtualenvs/stock_comms_analyzer_venv/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWebDriverException\u001b[0m: Message: chrome not reachable\n  (Session info: chrome=80.0.3987.100)\n  (Driver info: chromedriver=2.41.578700 (2f1ed5f9343c13f73144538f15c00b370eda6706),platform=Linux 5.3.0-40-generic x86_64)\n"
     ]
    }
   ],
   "source": [
    "start_time = (datetime.now())\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.set_page_load_timeout(30)\n",
    "    \n",
    "espi = []\n",
    "# The range of the id of reports to be scraped from gpw website \n",
    "for el in range(308451,310000,1):\n",
    "    url = 'https://www.gpw.pl/komunikat?geru_id='+str(el)\n",
    "    if os.path.exists(\"htmls/\"+str(el)+\".html\")==False:\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html)\n",
    "            with open(\"htmls/\"+str(el)+\".html\", \"w\") as file:\n",
    "                file.write(str(parse_url_and_save(soup)))\n",
    "        except:\n",
    "            1==1\n",
    "            # print(\"Error at id number: \"+str(el))\n",
    "\n",
    "driver.close()\n",
    "\n",
    "end_time = (datetime.now())\n",
    "print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Parse data from the scraped html files and save it to csv file to be used for further processing and modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To process ESPI files it took: 0:15:35.733726\n",
      "Total number of files processed: 23447\n",
      "Total number of ESPI information processed: 22333\n",
      "Total number of errors: 1114\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "path = './htmls'\n",
    "files = []\n",
    "# r=root, d=directories, f=files\n",
    "for r, d, f in os.walk(path):\n",
    "    for file in f:\n",
    "        if '.html' in file:\n",
    "            files.append(os.path.join(r, file))\n",
    "files.sort()\n",
    "\n",
    "dates=[]\n",
    "names=[]\n",
    "espi_filename=[]\n",
    "espi_info=[]\n",
    "espi_errors=[]\n",
    "errors=0\n",
    "\n",
    "for f in files:\n",
    "    url = str(f)\n",
    "    try:\n",
    "        soup = BeautifulSoup(open(f), \"html.parser\")\n",
    "        soup_text = parse_url(soup).lower()\n",
    "        dates.append(parse_date(soup))\n",
    "        names.append(parse_name(soup))\n",
    "        espi_info.append(soup_text)\n",
    "        espi_filename.append(f)\n",
    "        \n",
    "    except:\n",
    "        espi_errors.append(f)\n",
    "        errors+=1\n",
    "\n",
    "output = pd.DataFrame(list(zip(espi_filename,dates,names,espi_info)), \n",
    "                      columns=['filename','date','name','file_content'])\n",
    "output.to_csv('espi_data.csv', index=False)\n",
    "\n",
    "output_errors = pd.DataFrame(list(zip(espi_errors)), \n",
    "                      columns=['filename'])\n",
    "output_errors.to_csv('espi_errors.csv', index=False)\n",
    "\n",
    "end_time = datetime.now()\n",
    "time_taken = end_time-start_time\n",
    "print(f'To process ESPI files it took: {time_taken}')\n",
    "print(f'Total number of files processed: {len(files)}')\n",
    "print(f'Total number of ESPI information processed: {len(espi_info)}')\n",
    "print(f'Total number of errors: {errors}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
